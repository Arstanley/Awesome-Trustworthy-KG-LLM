# Awesome Trustworthy Retrieval Augmented Generation (RAG)
[![Awesome](https://awesome.re/badge.svg)](https://github.com/Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation/blob/main/LICENSE)
![](https://img.shields.io/badge/PRs-Welcome-red) 

> "The simple believes everything, but the prudent gives thought to his steps."
Proverbs 14:15 (ESV)

🙌 This repository collects papers investigating the trustworthiness of retrieval augmented generation.

😎 Welcome to recommend missing papers through **`Adding Issues`** or **`Pull Requests`**. 

<!-- Details of summary and classification of papers are shown in [wiki](https://github.com/zjukg/KG-LLM-Papers/wiki). -->

## 🔔 News
- **`2024-06` We create this repository to maintain a paper list on `Trustworthiness of the LLM Retrieval Augmented Generation paradigm`.**

<!--
*Todo:*
1. - [ ] `Fine-grained classification of papers`
2. - [ ] `Update paper project / code`
3. - [ ] `Wiki page for brief paper introduction`
-->
   
## Content


  
- [📜 Papers](#papers)
  - [📝 Surveys](#surveys)
    - [RAG](#rag)
    - [LLM Trustworthiness](#llm-trustworthiness)
  - [🔒 Privacy](#privacy)
  - [💪 Robustness](#robustness)
  - [⚖️ Fairness](#fairness)
  - [📖 Explainability](#explainability)
  - [🤖 Others](#others)
---
##  Papers

### Surveys
#### RAG
- \[[arxiv](https://arxiv.org/abs/2312.10997)\]\[[Github](https://github.com/Tongji-KGLLM/RAG-Survey)\] Retrieval-Augmented Generation for Large Language Models: A Survey. `2024.03`
- \[[arxiv](https://arxiv.org/abs/2405.07437)\] Evaluation of Retrieval-Augmented Generation: A Survey. `2024.05`
- \[[arxiv](https://arxiv.org/abs/2311.07914)\] Can Knowledge Graphs Reduce Hallucinations in LLMs? : A Survey. `2023.11`
- \[[arxiv](https://arxiv.org/abs/2310.07521)\] Survey on Factuality in Large Language Models: Knowledge, Retrieval and Domain-Specificity. `2023.10`
- \[[arxiv](https://arxiv.org/pdf/2306.11489.pdf)\] ChatGPT is not Enough: Enhancing Large Language Models with Knowledge Graphs for Fact-aware Language Modeling. `2023.06`
- \[[arxiv](https://arxiv.org/abs/2211.05994)\] A Survey of Knowledge-Enhanced Pre-trained Language Models. `2023.05`
- \[[Paper](https://arxiv.org/abs/2302.07842)\] Augmented Language Models: a Survey. `2023.02`
#### LLM Trustworthiness
- \[[arxiv](https://arxiv.org/abs/2306.11698)\]\[[Website](https://decodingtrust.github.io)\] DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models. `2024.02`
- \[[arxiv](https://arxiv.org/abs/2304.08979)\] In ChatGPT We Trust? Measuring and Characterizing the Reliability of ChatGPT. `2023.04`
- \[[arxiv](https://arxiv.org/abs/2303.00293)\] How Robust is GPT-3.5 to Predecessors? A Comprehensive Study on Language Understanding Tasks. `2023.03`
- \[[Paper](https://arxiv.org/abs/2210.09150)\] \[[Github](https://github.com/NoviScl/GPT3-Reliability)\] Prompting GPT-3 To Be Reliable. `2022.10`
### Privacy 
- \[[arxiv](https://arxiv.org/abs/2402.16893)\] The Good and The Bad: Exploring Privacy Issues in Retrieval-Augmented Generation (RAG). `2024.02`

### Robustness
- \[[arxiv](https://arxiv.org/abs/2406.00944)\] Unveil the Duality of Retrieval-Augmented Generation: Theoretical Analysis and Practical Solution. `2024.06`
- \[[arxiv](https://arxiv.org/abs/2405.20978)\]  Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training. `2024.05`
- \[[ICLR](https://openreview.net/forum?id=ZS4m74kZpH)\] Making Retrieval-Augmented Language Models Robust to Irrelevant Context. `2024.05`
- \[[arxiv](https://arxiv.org/abs/2403.14952)\] Evidence-Driven Retrieval Augmented Response Generation for Online Misinformation. `2024.03`

### Fairness
- \[[arxiv](https://arxiv.org/abs/2403.19964)\] FairRAG: Fair Human Generation via Fair Retrieval Augmentation. `2024.04`

### Explainability
- \[[arxiv](https://arxiv.org/abs/2310.01061)\] Reasoning on Graphs: Faithful and Interpretable Large Language Model Reasoning. `2024.02`
### Others
- \[[arxiv](https://arxiv.org/abs/2406.05794)\] RE-RAG: Improving Open-Domain QA Performance and Interpretability with Relevance Estimator in Retrieval-Augmented Generation. `2024.06`

## Contribution
### 👥 Contributors (🗣️ We don't have any yet but once you contribute your profile will be shown here!)
<a href="https://github.com/Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation/graphs/contributors">
  <img src="https://contrib.rocks/image?repo=Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation" />
</a>

### 🎉 Contributing ( welcome ! )
- ✨ Add a new paper or update an existing one.
- 🧐 Use the same format as existing entries to describe the work.
- 😄 A very brief explanation why you think a paper should be added or updated is recommended (Not Neccessary) via **`Adding Issues`** or **`Pull Requests`**.

**Don't worry if you put something wrong, they will be fixed for you. Just feel free to contribute and promote your awesome work here! 🤩 We'll get back to you in time ~ 😉**

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation&type=Date)](https://star-history.com/#Arstanley/Awesome-Trustworthy-Retrieval-Augmented-Generation&Date)
